{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!unzip \"../input/home-depot-product-search-relevance/train.csv.zip\"\n",
    "!unzip \"../input/home-depot-product-search-relevance/test.csv.zip\"\n",
    "!unzip \"../input/home-depot-product-search-relevance/product_descriptions.csv.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "home_df = pd.read_csv(\"./train.csv\",encoding='ISO-8859-1')\n",
    "home_product_desc = pd.read_csv(\"./product_descriptions.csv\")\n",
    "home_test_df = pd.read_csv(\"./test.csv\",encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df = pd.concat((home_df,home_test_df),axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df = pd.merge(home_df,home_product_desc,how = 'left',on='product_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df['product_info'] = home_df['product_title']+\" \"+home_df['product_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "home_df['relevance'] = home_df['relevance'].replace(np.nan,int(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_home_df = home_df[home_df['relevance']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_home_df = home_df[home_df['relevance']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_home_df = train_home_df.drop(['product_uid','product_title','product_description'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_home_df['relevance'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel,BertTokenizer,get_linear_schedule_with_warmup,AdamW,AutoTokenizer,AutoModel\n",
    "import tez\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tez.datasets import GenericDataset\n",
    "from tez import Model\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn import metrics,model_selection,preprocessing\n",
    "import torchvision\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_home_df,valid_home_df = train_test_split(train_home_df , test_size = 0.26, stratify = train_home_df.relevance.values, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_home_df = train_home_df.reset_index(drop=True)\n",
    "valid_home_df = valid_home_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class home_depot_Dataset(Dataset):\n",
    "    def __init__(self,df,tokenizer,max_len = 256):\n",
    "        self.search_term = df.search_term.values\n",
    "        self.product_info = df.product_info.values\n",
    "        self.target = df.relevance.values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        search_term = str(self.search_term[item])\n",
    "        search_term = ' '.join(search_term.split())\n",
    "        \n",
    "        product_info = str(self.product_info[item])\n",
    "        product_info = ' '.join(product_info.split())\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(search_term,\n",
    "                                            product_info,\n",
    "                                            add_special_tokens=True,\n",
    "                                            max_length=self.max_len,\n",
    "                                            padding=\"max_length\",\n",
    "                                            return_token_type_ids=True,\n",
    "                                            return_tensors=\"pt\",truncation=True)\n",
    "        \n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "        \n",
    "        return {\n",
    "            \n",
    "            \"input_ids\" : input_ids.squeeze(),\n",
    "            \"token_type_ids\" : token_type_ids.squeeze(),\n",
    "            \"attention_mask\" : attention_mask.squeeze(),\n",
    "            \"targets\" : torch.tensor(self.target[item], dtype = torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = home_depot_Dataset(train_home_df,tokenizer=tokenizer)\n",
    "valid_dataset = home_depot_Dataset(valid_home_df,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset[1]\n",
    "tokenizer.decode(data[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class home_depot__Model(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base_model =  AutoModel.from_pretrained(\"roberta-base\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(768,1)\n",
    "        self.step_scheduler_after = \"epoch\"\n",
    "        \n",
    "    def monitor_metrics(self, outputs,targets):\n",
    "        if targets is None:\n",
    "            return {}\n",
    "        outputs = torch.sigmoid(outputs).cpu().detach().numpy() >= 0.5\n",
    "        targets = targets.cpu().detach().numpy()\n",
    "        accuracy = metrics.r2_score(targets, outputs)\n",
    "        return {\"r2_score\": accuracy}\n",
    "    \n",
    "    def fetch_optimizer(self):\n",
    "        model = self.base_model\n",
    "        no_decay = [\"bias\",\"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.001,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n",
    "        opt = optimizer\n",
    "        return opt\n",
    "    \n",
    "    def fetch_scheduler(self):\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer, num_warmup_steps=0, num_training_steps=len(self.train_loader)\n",
    "        )\n",
    "        return scheduler\n",
    "            \n",
    "        \n",
    "        \n",
    "    def forward(self,input_ids,token_type_ids = None,attention_mask = None,targets = None):\n",
    "        _, o_2 = self.base_model(input_ids=input_ids, \n",
    "                                 attention_mask=attention_mask,\n",
    "                                 token_type_ids=token_type_ids)\n",
    "        b_o = self.dropout(o_2)\n",
    "        output = self.out(b_o)\n",
    "        if targets is not None:\n",
    "                    # calculate loss here\n",
    "            loss = nn.MSELoss()(output, targets.view(-1,1))\n",
    "            metrics = self.monitor_metrics(output, targets)\n",
    "            return output, loss, metrics\n",
    "\n",
    "\n",
    "        return output, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = home_depot__Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tez.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor=\"valid_loss\",mode= \"min\" ,model_path=\"model.bin\",patience=3)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset=train_dataset,\n",
    "    valid_dataset=valid_dataset,\n",
    "    train_bs=16,\n",
    "    valid_bs=8,\n",
    "    device=\"cuda\",\n",
    "    epochs=5,\n",
    "    callbacks= [es],\n",
    "    fp16=True\n",
    "\n",
    ")\n",
    "model.save(\"model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = home_depot_Dataset(test_home_df,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset[102]\n",
    "tokenizer.decode(data[\"input_ids\"])\n",
    "data[\"targets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(data,model):\n",
    "   \n",
    "    input_ids = data[\"input_ids\"].unsqueeze(0)\n",
    "    token_type_ids = data[\"token_type_ids\"].unsqueeze(0)\n",
    "    attention_mask = data[\"attention_mask\"].unsqueeze(0)\n",
    "    targets = data[\"targets\"].unsqueeze(0)\n",
    "\n",
    "    output,loss,metr = model(input_ids,attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids,targets = targets)\n",
    "    print(output)\n",
    "    return out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentence(data,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = None\n",
    "for j in range(1):\n",
    "    preds = model.predict(test_dataset, batch_size=256, n_jobs=-1, device=\"cuda\")\n",
    "    temp_preds = None\n",
    "    for p in preds:\n",
    "        if temp_preds is None:\n",
    "            temp_preds = p\n",
    "        else:\n",
    "            temp_preds = np.vstack((temp_preds, p))\n",
    "    if final_preds is None:\n",
    "        final_preds = temp_preds\n",
    "    else:\n",
    "        final_preds += temp_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
